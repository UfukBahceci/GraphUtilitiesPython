{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd2d69f-ec4f-4f7e-a460-45809a5d9250",
   "metadata": {},
   "source": [
    "# A Short Intro to Distance Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e94650-5695-45d2-9fb8-e8658567d53c",
   "metadata": {},
   "source": [
    "We know that vertices and edges are basic elements used to create a graph. When nodes carry a set of numerical values that have the potential to describe the relationships between them, it is possible to use these numerical values to formulate distances on edges between nodes. In this tutorial we will learn some basic distance types used in formulating the relationships between nodes in a graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079cdb51-d1d9-43de-90fc-83502ad8d740",
   "metadata": {},
   "source": [
    "Let the column vectors $\\mathbf{x^1}$ and $\\mathbf{x^2}$ be the numerical values associated with the nodes $1$ and $2$, respectively. Let $x^1_j$ denote the numerical value associated with the node $1$ at the $j^{th}$ dimension. In the following, we define some basic distance types used to model the relationship between the nodes $1$ and $2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16a5e6f-0cdc-4ce8-9f70-58a2717375c3",
   "metadata": {},
   "source": [
    "# Rectilinear Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf38d98d-e9cb-4649-8c5c-374f894cf87c",
   "metadata": {},
   "source": [
    "$D_{Rectilinear}(\\mathbf{x^1},\\mathbf{x^2})=\\sum\\limits_{j}|x^1_j - x^2_j|$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc346d6-3741-4efc-9a36-0349e59a9812",
   "metadata": {},
   "source": [
    "The rectilinear (Manhattan) distance ($\\in [0,\\infty)$) is equal to the sum of displacements in orthogonal directions in order to move from one location to another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3943652-d391-4da6-9774-1f64ee4d1070",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Euclidean Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d08bcb2-581e-4273-a711-d16972ec0b75",
   "metadata": {},
   "source": [
    "$D_{Euclidean}(\\mathbf{x^1},\\mathbf{x^2})=\\sqrt{\\sum\\limits_{j}(x^1_j - x^2_j)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a43184f-40e2-4ca9-8ba6-a05dad8edf2e",
   "metadata": {},
   "source": [
    "The Euclidiean distance ($\\in [0,\\infty)$) is equal to the length of the line segment between two locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f684f8ef-c882-4b0b-a293-0818d8cc1cc3",
   "metadata": {},
   "source": [
    "# Chebyshev Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8855ea3-7417-4a13-92d9-396b6c75e6b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "$D_{Chebyshev}(\\mathbf{x^1},\\mathbf{x^2})=\\max\\limits_{j}(| x^1_j - x^2_j |)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba79a8-2bc9-453b-9ca4-c9fec5490bb3",
   "metadata": {},
   "source": [
    "The Chebyshev distance ($\\in [0,\\infty)$) can be used to model the time required to move a crane from one location to another, where locations are arranged in the form of a rectangular grid. Here, we assume that the crane has identical motors or movement speeds in all (usually two) directions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950bd1e-8957-4149-80b1-58bc369f7b48",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cosine Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78457a02-bdb0-45db-8856-7dd17d4332ce",
   "metadata": {},
   "source": [
    "$S_{Cosine}(\\mathbf{x^1},\\mathbf{x^2})=\\frac{\\mathbf{x^1}^\\top \\mathbf{x^2}}{||\\mathbf{x^1}||\\,||\\mathbf{x^2}||}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb58aca-670b-4faa-9019-ae267809af9a",
   "metadata": {},
   "source": [
    "The cosine similarity ($\\in [-1,1]$) is equal to the cosine of the angle between the vectors $\\mathbf{x^1}$ and $\\mathbf{x^2}$. The centered cosine similarity ($\\in [-1,1]$) is defined as follows: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cedc9b-2c01-43fc-b276-05c10d414725",
   "metadata": {},
   "source": [
    "$S_{CenteredCosine}(\\mathbf{x^1},\\mathbf{x^2})=\\frac{(\\mathbf{x^1}-\\overline{\\mathbf{x^1}})^\\top (\\mathbf{x^2}-\\overline{\\mathbf{x^2}})}{||\\mathbf{x^1}-\\overline{\\mathbf{x^1}}||\\,||\\mathbf{x^2}-\\overline{\\mathbf{x^2}}||}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24153223-a2ff-4761-87dc-4635a20a77ca",
   "metadata": {},
   "source": [
    "Note that the centered cosine similarity is equal to the sample Pearson correlation coefficient $r_{\\mathbf{x^1}\\mathbf{x^2}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096747bb-513e-43b0-ac30-264203857f96",
   "metadata": {},
   "source": [
    "The cosine distance ($\\in [0,2]$) is defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7332b8b9-1362-4a74-9062-f05d2dc8d418",
   "metadata": {},
   "source": [
    "$D_{Cosine}(\\mathbf{x^1},\\mathbf{x^2})=1-S_{Cosine}(\\mathbf{x^1},\\mathbf{x^2})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e703e-fd05-4f93-8ee5-63ef6f08cbd0",
   "metadata": {},
   "source": [
    "# Jaccard Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96b4ef-68bc-4c61-89dc-82506da436f7",
   "metadata": {},
   "source": [
    "The Jaccard coefficient ($\\in [0,1]$) can be used to measure the similarity between finite sample sets. Let $\\mathcal{X^1}=\\{x^1_1, \\dots x^1_j, \\dots , x^1_d \\}$ denote the finite sample set consisting of $d$ elements, where $d$ is the dimension of the vector $\\mathbf{x^1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c50be-e747-4688-896c-4ea542a4e369",
   "metadata": {},
   "source": [
    "$S_{Jaccard}(\\mathcal{X^1},\\mathcal{X^2})=\\frac{|\\mathcal{X^1} \\cap \\mathcal{X^2}|}{|\\mathcal{X^1} \\cup \\mathcal{X^2}|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f9f314-3d24-41f9-ae12-80b9af95ed02",
   "metadata": {},
   "source": [
    "Then the Jaccard distance ($\\in [0,1]$) can be defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf1a0d-b68a-4996-9644-ad2821ec0445",
   "metadata": {},
   "source": [
    "$D_{Jaccard}(\\mathcal{X^1},\\mathcal{X^2})=1-S_{Jaccard}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5d4d1-d75a-4b20-b2e6-12e57ae012e7",
   "metadata": {},
   "source": [
    "When there are $d$ attributes in total and the $d$-dimensional vector $\\mathbf{x^1}$ holds binary data, where the binary value at the $j^{th}$ dimension for the node $1$ indicates whether the $j^{th}$ attribute is an element of the node $1$, we consider the binary Jaccard distance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3282f588-b0a8-4bc3-93fa-ca3a9cea19c6",
   "metadata": {},
   "source": [
    "$S_{binaryJaccard}(\\mathbf{x^1},\\mathbf{x^2})=\\frac{||\\mathbf{x^1} \\land \\mathbf{x^2}||_1}{d-||\\lnot\\mathbf{x^1} \\land \\lnot\\mathbf{x^2}||_1}=\\frac{TP}{FP+FN+TP}$,  where $\\land$ is for AND and $\\lnot$ is for NOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f3c5a6-133e-4da2-9d51-9245d48068b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "$D_{binaryJaccard}(\\mathbf{x^1},\\mathbf{x^2})=1-S_{binaryJaccard}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16469f7-219b-47d2-aaec-24501b6cde74",
   "metadata": {},
   "source": [
    "# Sørensen–Dice Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f69a65f-9e67-4fa0-ae21-e7aa4810f9ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "The Sørensen–Dice coefficient ($\\in [0,1]$) measures the similarity between finite sample sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb21f5a-fd0e-4baf-9692-4e906375e6a5",
   "metadata": {},
   "source": [
    "$S_{SorensenDice}(\\mathcal{X^1},\\mathcal{X^2})=\\frac{2|\\mathcal{X^1} \\cap \\mathcal{X^2}|}{|\\mathcal{X^1}| + |\\mathcal{X^2}|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfc9a4e-bee3-4bbf-a0f9-3a0d052468ba",
   "metadata": {},
   "source": [
    "Then the Sørensen-Dice distance ($\\in [0,1]$) can be defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e025ddf-0c55-497a-8d34-9f85044271ae",
   "metadata": {},
   "source": [
    "$D_{SorensenDice}(\\mathcal{X^1},\\mathcal{X^2})=1-S_{SorensenDice}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc07614-585c-4103-a08b-0604a70f05f2",
   "metadata": {},
   "source": [
    "When there are $d$ attributes in total and the $d$-dimensional vector $\\mathbf{x^1}$ holds binary data, where the binary value at the $j^{th}$ dimension for the node $1$ indicates whether the $j^{th}$ attribute is an element of the node $1$, we consider the binary Sørensen-Dice distance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf34b4a-1066-4551-91d8-c2ad0f0b009f",
   "metadata": {},
   "source": [
    "$S_{binarySorensenDice}(\\mathbf{x^1},\\mathbf{x^2})=\\frac{2||\\mathbf{x^1} \\land \\mathbf{x^2}||_1}{||\\mathbf{x^1}||_1 + ||\\mathbf{x^2}||_1}=\\frac{2TP}{FP+FN+2TP}$ ($F_1$ score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c422285e-cc5d-44c0-b6d3-10762fc3e07b",
   "metadata": {},
   "source": [
    "$D_{binarySorensenDice}(\\mathbf{x^1},\\mathbf{x^2})=1-S_{binarySorensenDice}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c8cd8-4b7a-46d0-b238-b9f7bc64efd0",
   "metadata": {},
   "source": [
    "Note that,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ab583f-3a01-42fa-a4b5-09ece64abf2a",
   "metadata": {},
   "source": [
    "$S_{Jaccard}=\\frac{S_{SorensenDice}}{2-S_{SorensenDice}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c411168b-0135-4fc6-a29e-903273d977d8",
   "metadata": {},
   "source": [
    "$S_{SorensenDice}=\\frac{2S_{Jaccard}}{1+S_{Jaccard}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af8b0e-e39c-4096-bff2-e41a646cf4b3",
   "metadata": {},
   "source": [
    "# Hellinger Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bfa918-abfb-46c6-a643-7c771f710883",
   "metadata": {},
   "source": [
    "The Hellinger distance measures the dissimilarity between two probability distributions defined over the same probability space. When the probability distributions are discrete with probabilities $\\mathbf{x^1}$ and $\\mathbf{x^2}$, we can express the discrete Hellinger distance ($\\in [0,1]$) as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd53012-9c12-42b5-b2e8-0a9bc857c2be",
   "metadata": {},
   "source": [
    "$D_{discreteHellinger}(\\mathbf{x^1},\\mathbf{x^2})=\\frac{1}{\\sqrt{2}}\\sqrt{\\sum_{j=1}^{d}(\\sqrt{x^1_j}-\\sqrt{x^2_j})^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f743af0d-c521-4602-bb51-d5ccc375146a",
   "metadata": {},
   "source": [
    "# Kullback–Leibler Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9a0563-68b2-4b21-a733-9b317bd4d987",
   "metadata": {},
   "source": [
    "The Kullback–Leibler divergence is the relative entropy from a probabiliy distribution $\\mathcal{P}^1$ with probabilities $\\mathbf{x^1}$ to another probability distribution $\\mathcal{P}^2$ with probabilities $\\mathbf{x^2}$ defined over the same probability space. In the discrete case, Kullback-Leibler divergence ($\\in [0,\\infty)$) has the following form:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434672df-dac0-4878-9730-276c836d9677",
   "metadata": {},
   "source": [
    "$D_{discreteKL}(\\mathcal{P}^2 \\parallel \\mathcal{P}^1)=\\sum_{j=1}^{d} x^2_j \\log \\left({\\frac {x^2_j}{x^1_j}}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de575b4a-d230-4a18-b56b-06fa1827584b",
   "metadata": {},
   "source": [
    "# Hamming Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34ec95d-5eda-4caa-92f3-00b722d967ba",
   "metadata": {},
   "source": [
    "The Hamming distance between two strings of equal size is the number of alphabets that differ in the same positions. When the data is binary, the binary Hamming distance ($\\in \\{0,\\dots,d\\}$) can be defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd1a739-49a9-4ac9-9021-ccc86d87afe4",
   "metadata": {},
   "source": [
    "$D_{binaryHamming}(\\mathbf{x^1},\\mathbf{x^2})=||\\mathbf{x^1} \\mathbin{\\dot\\lor} \\mathbf{x^2}||_1$, where $\\mathbin{\\dot\\lor}$ is for XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2ae666-c236-4ff9-8953-d65a252b90d2",
   "metadata": {},
   "source": [
    "# Levenshtein Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcdbf89-f3f9-4c22-a89c-413246d45ce9",
   "metadata": {},
   "source": [
    "The Levenshtein distance can be used to measure the difference between two strings of different sizes. The Levenshtein distance is equal to the minimum number of atomic operations (insertions, deletions or substitutions of characters) performed while converting one word into another."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
